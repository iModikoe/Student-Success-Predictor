{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 03 – Modeling"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import json\nimport joblib\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n\n# Choose dataset: engineered or raw\nDATA_PATH = Path('../data/student-mat.csv')\nif not DATA_PATH.exists():\n    DATA_PATH = Path('../data/student-mat.csv')\ndf = pd.read_csv(DATA_PATH)\n\n# Ensure target column exists\nif 'passed' not in df.columns:\n    if 'final_grade' in df.columns:\n        df['passed'] = (df['final_grade'] >= 10).astype(int)\n    else:\n        raise ValueError(\"Dataset must include 'passed' or 'final_grade' to create it.\")\n\ntarget = 'passed'\nX = df.drop(columns=[target])\ny = df[target]\n\n# Identify column types\ncategorical_cols = [c for c in X.columns if X[c].dtype == 'object']\nnumeric_cols = [c for c in X.columns if c not in categorical_cols]\n\n# Preprocess\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numeric_cols),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n    ]\n)\n\nmodels = {\n    \"logreg\": LogisticRegression(max_iter=200, class_weight='balanced'),\n    \"dtree\": DecisionTreeClassifier(random_state=42),\n    \"rf\": RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced'),\n    \"xgb\": XGBClassifier(\n        n_estimators=300, learning_rate=0.08, max_depth=5, subsample=0.9, colsample_bytree=0.9,\n        reg_lambda=1.0, random_state=42, eval_metric='logloss', n_jobs=-1\n    )\n}\n\nresults = []\nbest_name, best_score, best_pipeline = None, -1.0, None\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nfor name, clf in models.items():\n    pipe = Pipeline(steps=[('pre', preprocessor), ('clf', clf)])\n    pipe.fit(X_train, y_train)\n\n    y_pred = pipe.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n\n    results.append((name, acc, prec, rec, f1))\n    if acc > best_score:\n        best_score = acc\n        best_name = name\n        best_pipeline = pipe\n\nprint(\"Model Results (name, acc, prec, rec, f1):\")\nfor row in results:\n    print(row)\n\nprint(f\"Best model: {best_name} (acc={best_score:.3f})\")\nprint(\"\\nClassification report for best model:\")\nprint(classification_report(y_test, best_pipeline.predict(X_test), zero_division=0))\n\n# Save artifacts\nART = Path('../artifacts/math')\nART.mkdir(exist_ok=True, parents=True)\njoblib.dump(best_pipeline, ART / 'best_model.joblib')\nprint(\"Saved best model → artifacts/best_model.joblib\")\n\n# Save schema for the app to render inputs\nschema = []\nfor col in X.columns:\n    typ = 'numeric' if col in numeric_cols else 'categorical'\n    cats = sorted(df[col].dropna().unique().tolist()) if typ == 'categorical' else None\n    # Limit very high-cardinality to avoid huge dropdowns\n    if cats is not None and len(cats) > 30:\n        cats = cats[:30]\n    schema.append({\"name\": col, \"type\": typ, \"categories\": cats})\nwith open(ART / 'feature_schema.json', 'w', encoding='utf-8') as f:\n    json.dump(schema, f, ensure_ascii=False, indent=2)\nprint(\"Saved schema → artifacts/feature_schema.json\")\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}