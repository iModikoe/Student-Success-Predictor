{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffe6608d",
   "metadata": {},
   "source": [
    "# 03 â€“ Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "\n",
    "# Choose dataset: engineered or raw\n",
    "DATA_PATH = Path('../data/student-mat.csv')\n",
    "if not DATA_PATH.exists():\n",
    "    DATA_PATH = Path('../data/student-mat.csv')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Ensure target column exists\n",
    "if 'passed' not in df.columns:\n",
    "    if 'final_grade' in df.columns:\n",
    "        df['passed'] = (df['final_grade'] >= 10).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset must include 'passed' or 'final_grade' to create it.\")\n",
    "\n",
    "target = 'passed'\n",
    "\n",
    "# Start with all features except the target\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "# ðŸš« Prevent leakage: drop final grade (G3)\n",
    "if \"G3\" in X.columns:\n",
    "    X = X.drop(columns=[\"G3\"])\n",
    "\n",
    "y = df[target]\n",
    "\n",
    "print(\"Features used for training:\", X.columns.tolist())\n",
    "print(\"Target:\", target)\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = [c for c in X.columns if X[c].dtype == 'object']\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "# Preprocess\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"logreg\": LogisticRegression(max_iter=200, class_weight='balanced'),\n",
    "    \"dtree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"rf\": RandomForestClassifier(n_estimators=300, random_state=42, class_weight='balanced'),\n",
    "    \"xgb\": XGBClassifier(\n",
    "        n_estimators=300, learning_rate=0.08, max_depth=5, subsample=0.9, colsample_bytree=0.9,\n",
    "        reg_lambda=1.0, random_state=42, eval_metric='logloss', n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_name, best_score, best_pipeline = None, -1.0, None\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline(steps=[('pre', preprocessor), ('clf', clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
    "\n",
    "    results.append((name, acc, prec, rec, f1))\n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_name = name\n",
    "        best_pipeline = pipe\n",
    "\n",
    "print(\"Model Results (name, acc, prec, rec, f1):\")\n",
    "for row in results:\n",
    "    print(row)\n",
    "\n",
    "print(f\"Best model: {best_name} (acc={best_score:.3f})\")\n",
    "print(\"\\nClassification report for best model:\")\n",
    "print(classification_report(y_test, best_pipeline.predict(X_test), zero_division=0))\n",
    "\n",
    "# Save artifacts\n",
    "ART = Path('../artifacts')\n",
    "ART.mkdir(exist_ok=True, parents=True)\n",
    "joblib.dump(best_pipeline, ART / 'best_model.joblib')\n",
    "print(\"Saved best model â†’ artifacts/best_model.joblib\")\n",
    "\n",
    "# Save schema for the app to render inputs\n",
    "schema = []\n",
    "for col in X.columns:\n",
    "    typ = 'numeric' if col in numeric_cols else 'categorical'\n",
    "    cats = sorted(df[col].dropna().unique().tolist()) if typ == 'categorical' else None\n",
    "    # Limit very high-cardinality to avoid huge dropdowns\n",
    "    if cats is not None and len(cats) > 30:\n",
    "        cats = cats[:30]\n",
    "    schema.append({\"name\": col, \"type\": typ, \"categories\": cats})\n",
    "with open(ART / 'feature_schema.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(schema, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved schema â†’ artifacts/feature_schema.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
